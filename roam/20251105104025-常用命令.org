:PROPERTIES:
:ID:       90d22d82-7525-4b3c-82ea-0dea0b44b91c
:END:
#+title: 常用命令
* 2025-11-04 Tue
:PROPERTIES:
:CATEGORY: 服务优化
:END:

* TODO 根据 trace 分析 kafka 消费链路，如何提高消费速度
** TODO 确定性能瓶颈点
   - 分析 Kafka 拉取数据是否慢？（目前 64 线程并发拉取？速度不应该慢）
   - 检查落库速度是否慢？
   - 检查 ACK 确认数据是否慢？

** TODO 目前三个主题(create,update,delete)分区都是 64 个，把 fetchetchloop 改为多 reader
当前的消费链路已经已经已经按照 KafkaKafkaOptions.FetcherCount 启动多 reader：
在 consumer.go 的 NewUserConsumer 里会根据 FetcherCount 构造 len(c.readers) 个 kafka.Reader，StartConsuming 会为每个 reader 启一个 runFetchLoop 并发拉取消息。
每条消息携带的 readerIdx 会一路透透传到 worker、batch 聚合器，再由提交协程调用 commitWithRetry 时选回对应 reader 进行 commit，避免多 reader 下的提交错配。
create/delete/update 这三类操作走的就是同一套 pipeline：正常情况下直接由 worker 处理；当队列阻塞时会进入 runBatchAggregator 做批量写库，仍然保留原始的 readerIdx，所以这几类操作同样受益于多 reader。
如果想继续加大并发，只需要在配置里把 FetcherCount 调高（或设置环境变量 KAFKA_FETCHER_COUNT），重启实例即可生效。

* 开启数据库慢查询记录及重置相关日志
1. 开启慢查询日志；如需永久生效，将同样配置写入 my.cnf [mysqld] 段。
#+begin_src
SET GLOBAL slow_query_log = ON;
SET GLOBAL long_query_time = 0.2;
SET GLOBAL log_output = 'TABLE';
#+end_src


2. 打开 Performance Schema 等待事件
#+begin_src
UPDATE performance_schema.setup_instruments
   SET ENABLED='YES', TIMED='YES'
 WHERE NAME IN ('wait/lock/%','wait/synch/%');
UPDATE performance_schema.setup_consumers
   SET ENABLED='YES'
 WHERE NAME IN ('events_waits_current','events_waits_history','events_waits_history_long');
#+end_src
验证
#+begin_src
SHOW VARIABLES LIKE 'slow_query%';
SELECT COUNT(*) FROM mysql.slow_log;
SELECT * FROM performance_schema.events_waits_summary_global_by_event_name WHERE AVG_TIMER_WAIT>0 ORDER BY SUM_TIMER_WAIT DESC LIMIT 20;
#+end_src

3. 重置相关日志
   #+begin_src
-- 重置相关的事件表
TRUNCATE TABLE performance_schema.events_statements_summary_by_digest;
TRUNCATE TABLE performance_schema.events_statements_history_long;
TRUNCATE TABLE mysql.slow_log;

   #+end_src
