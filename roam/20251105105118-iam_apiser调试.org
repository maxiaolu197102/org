:PROPERTIES:
:ID:       2741c751-fb9c-4837-b92a-9b2b35d3309c
:END:
#+title: iam apiser调试

* 2025-11-04 Tue
:PROPERTIES:
:CATEGORY: 服务优化
:END:

* DONE 根据trace分析kafka消费链路，如何提高消费速度
** DONE 确定性能瓶颈点
   - 分析Kafka拉取数据是否慢？（目前64线程并发拉取？速度不应该慢）
   - 检查落库速度是否慢？
   - 检查ACK确认数据是否慢？

** DONE 目前三个主题(create,update,delete)分区都是64个，把fetchetchloop改为多reader
当前的消费链路已经已经已经按照 KafkaKafkaOptions.FetcherCount 启动多 reader：
在 consumer.go 的 NewUserConsumer 里会根据 FetcherCount 构造 len(c.readers) 个 kafka.Reader，StartConsuming 会为每个 reader 启一个 runFetchLoop 并发拉取消息。
每条消息携带的 readerIdx 会一路透透传到 worker、batch 聚合器，再由提交协程调用 commitWithRetry 时选回对应 reader 进行 commit，避免多 reader 下的提交错配。
create/delete/update 这三类操作走的就是同一套 pipeline：正常情况下直接由 worker 处理；当队列阻塞时会进入 runBatchAggregator 做批量写库，仍然保留原始的 readerIdx，所以这几类操作同样受益于多 reader。
如果想继续加大并发，只需要在配置里把 FetcherCount 调高（或设置环境变量 KAFKA_FETCHER_COUNT），重启实例即可生效。

** DONE 把消费线路上关键点全部进行span埋点
消费环节：StartConsuming 的分发、runFetchLoop 的每次次取消息尝试、worker 侧 processMessageWithRetry 的多次重试流程。
批处理阶段：batchCreateToDB、batchDeleteFromDB、batchUpdateToDB 各自的批次大小、成功条数和失败原因。
数据库操作：单条的 createUserInDB、updateUserInDB、deleteUserFromDB，都会记录执行耗时、重试次数、版本冲突等细节。
缓存及清理：setUserCache、purgeUserState 等操作新增 span，展示缓存写入、负缓存清理和 session 清理是否成功。
其他关键步骤例如提交偏移 (commitWithRetry)、pending marker 验证、批量聚合器等也保留原有或新增标签。
所有新增 span 都带有 topic、partition、offset、reader/worker 编号、批次统计等标签，便于在链路追踪里快速定位瓶颈。

** DONE 消费差异分析
- Prometheus 截图显示 user.create.v1 每秒生产≈241 c/s，但消费≈1 c/s、提交≈1.3 c/s，累计滞后 46；user.update.v1 则消费≈318 c/s、生产≈320 c/s，滞后仅 146。后者与我们之前 64 线程基线相近，说明 Kafka→DB 链路在 update/delete 上仍然健康。
- consumer.go 中的创建流程在真正写库前要做 Redis pending marker 校验、可能的 DB 快照兜底，再 insert、写缓存、清 marker（参见 processCreateOperation 及 getPendingCreateMarker）。这些步骤都在单条消息上串行执行，如果 Redis 操作超时或 marker 缺失导致兜底查询，就会把单条处理时间拉长到秒级；Kafka 每分区还是串行提交 offset，所以整体吞吐被拖成 "1 c/s"。
- 新增 fetcher/worker 后提升有限，是因为瓶颈在单条消息的 IO（Redis/DB/重试写 Kafka），不是 goroutine 数量。即便 WorkerCount 拉到 64，单条仍需等待 Redis→MySQL→Redis，全局吞吐≈分区数 × 单条耗时的倒数；若单条耗时 700–1000 ms，理论上限就是 1–1.4 c/s，和监控吻合。
- Update/Delete 路径没有 pending marker 校验，主要是批量更新/删除逻辑（batchUpdateToDB/batchDeleteFromDB），加上缓存刷新，单条通常几十毫秒，因此能够跟上生产速率，也印证了"每秒小飞鼠≈每秒提交"只代表 DB 提交没有拖慢，而不是说 create 没有瓶颈。
=定位建议=
- 用我们刚加的 trace span：重点看 pending_marker_verify、persist_user、clear_pending_marker 的 duration_ms、pending_marker_get_ms、redis_get_ms 等标签，确认延迟落在哪个阶段；也留意 trace 里的 pending_marker_missing、pending_marker_degraded、pending_marker_clear_error，判断是否频繁兜底或清理失败。

- 同时查看 metrics.ConsumerProcessingErrors 与 ConsumerRetryMessages（operation=create），如果大量报 PENDING_MARKER_ERROR / CHECK_EXISTING_FAILED / CREATE_DB_ERROR，说明我们在写 retry topic；若 retry 阻塞（producer.sendToRetryTopic 返回 enqueue retry topic failed），consumer 会不断重试同一 offset，吞吐进一步被压低。
- 关注 Redis 客户端指标或日志，确认连接池（默认 500）是否耗尽、是否存在 5 s timeout；必要时在 Redis 侧抓取 QPS/慢查询。
* DONE 任务
** DONE 目标：确定 create 链路哪一段最慢，为后续改造提供依据。
做法：从 log/perf/ 或 trace 输出目录抽取最近压测时间段的 trace JSON/NDJSON（例如 grep batch_create_db、pending_marker_*），统计关键 span（pending_marker_verify、persist_user、clear_pending_marker、process_with_retry）的 p50/p95。
产出：一份对比表，列出各阶段平均/95线耗时，并附带 sample trace 链接或文件路径。

** DONE 调整 fetch loop 让 create 优先走 batch（优先级 P1）
目标：减少单条串行开销，让 insert 真正批量化。
方案草案：在 runFetchLoop 中对 OperationCreate 的消息直接推入 batchCh，仅当 batch channel 接近满时再 fallback 到 jobs；同时可把 batch worker 数与 create 消费比绑定，确保 batch aggregator 能利用最大批次。
需要代码改动 + gofmt/go test 验证。

** DONE PromQL 告警 for pending_marker（优先级 P2）
目标：监控 Redis pending marker 相关异常（耗时、失败率、缺失）。
产出：PromQL 查询 & 告警规则草稿（例如：
increase(redis_pending_marker_get_seconds_sum[5m]) / increase(redis_pending_marker_get_seconds_count[5m]) > 阈值
increase(consumer_retry_messages_total{operation="create",error_type="pending_marker_error"}[5m]) > 0
或 sum(rate(pending_marker_missing_total[5m]))）。
可配合 Grafana 面板或 Alertmanager 规则。

** DONE ** TODO 需要分析批量链路，编写相应场景并收集trace指标
用 k6 跑 10 分钟压测，建议包含「基线串行」「高并发 create」「重复校验」「校验失败」四个场景，能覆盖多 reader、批量写入、pending marker 路径。
